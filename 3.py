import requests
import pandas as pd
import datetime as dt
import json
import os

def scrape_cnyes_news():
    """çˆ¬å–é‰…äº¨ç¶²æ–°èä¸¦é©—è­‰æˆåŠŸ"""
    try:
        print("ğŸš€ é–‹å§‹çˆ¬å–é‰…äº¨ç¶²æ–°è...")
        
        data = []
        url = "https://api.cnyes.com/media/api/v1/newslist/category/headline"
        payload = {
            "page": 1,
            "limit": 30,
            "isCategoryHeadline": 1,
            "startAt": int((dt.datetime.today() - dt.timedelta(days=10)).timestamp()),
            "endAt": int(dt.datetime.today().timestamp())
        }
        
        # ç²å–ç¬¬ä¸€é 
        print("ğŸ“¥ æ­£åœ¨ç²å–ç¬¬1é ...")
        res = requests.get(url, params=payload, timeout=30)
        res.raise_for_status()  # æª¢æŸ¥HTTPéŒ¯èª¤
        
        jd = json.loads(res.text)
        data.append(pd.DataFrame(jd['items']['data']))
        
        total_pages = jd['items']['last_page']
        print(f"ğŸ“„ ç¸½å…±ç™¼ç¾ {total_pages} é ")
        
        # ç²å–å…¶ä»–é é¢
        for i in range(2, total_pages + 1):
            print(f"ğŸ“¥ æ­£åœ¨ç²å–ç¬¬ {i}/{total_pages} é ...")
            payload["page"] = i
            
            res = requests.get(url, params=payload, timeout=30)
            res.raise_for_status()
            jd = json.loads(res.text)
            data.append(pd.DataFrame(jd['items']['data']))
        
        # è™•ç†è³‡æ–™
        df = pd.concat(data, ignore_index=True)
        df = df[['newsId', 'title', 'summary']]
        df['link'] = df['newsId'].apply(lambda x: f'https://m.cnyes.com/news/id/{x}')
        
        # ä¿å­˜æª”æ¡ˆ
        filename = 'news.csv'
        df.to_csv(filename, encoding='utf-8-sig', index=False)
        
        # é©—è­‰æˆåŠŸ
        if os.path.exists(filename):
            file_size = os.path.getsize(filename)
            print(f"âœ… çˆ¬å–æˆåŠŸ!")
            print(f"ğŸ“Š ç¸½å…±ç²å– {len(df)} ç­†æ–°è")
            print(f"ğŸ’¾ æª”æ¡ˆå·²ä¿å­˜: {filename} ({file_size} bytes)")
            print(f"ğŸ“‹ æ¬„ä½: {', '.join(df.columns)}")
            
            # é¡¯ç¤ºç¯„ä¾‹
            print("\nğŸ“° æ–°èç¯„ä¾‹:")
            for i, row in df.head(3).iterrows():
                print(f"  {i+1}. {row['title'][:50]}...")
            
            return True
        else:
            print("âŒ æª”æ¡ˆä¿å­˜å¤±æ•—")
            return False
            
    except requests.RequestException as e:
        print(f"âŒ ç¶²è·¯è«‹æ±‚éŒ¯èª¤: {e}")
        return False
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æéŒ¯èª¤: {e}")
        return False
    except Exception as e:
        print(f"âŒ æœªçŸ¥éŒ¯èª¤: {e}")
        return False

if __name__ == "__main__":
    success = scrape_cnyes_news()
    if success:
        print("ğŸ‰ ç¨‹å¼åŸ·è¡ŒæˆåŠŸ!")
    else:
        print("ğŸ’¥ ç¨‹å¼åŸ·è¡Œå¤±æ•—!")