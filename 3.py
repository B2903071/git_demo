import json
import pandas as pd
import os
import re

def fix_json_trailing_commas(json_string):
    """ä¿®å¾© JSON ä¸­çš„å°¾éš¨é€—è™Ÿå•é¡Œ"""
    # ç§»é™¤ç‰©ä»¶ä¸­æœ€å¾Œä¸€å€‹å±¬æ€§å¾Œçš„é€—è™Ÿ
    json_string = re.sub(r',(\s*})', r'\1', json_string)
    # ç§»é™¤é™£åˆ—ä¸­æœ€å¾Œä¸€å€‹å…ƒç´ å¾Œçš„é€—è™Ÿ
    json_string = re.sub(r',(\s*])', r'\1', json_string)
    return json_string

def advanced_json_fix(json_string):
    """é€²éš JSON ä¿®å¾©åŠŸèƒ½"""
    # ç§»é™¤å¤šé¤˜çš„ç©ºç™½å’Œæ›è¡Œ
    lines = json_string.split('\n')
    cleaned_lines = []
    
    for line in lines:
        stripped = line.strip()
        if stripped and not stripped.startswith('//'):  # ç§»é™¤ç©ºè¡Œå’Œè¨»é‡‹
            cleaned_lines.append(stripped)
    
    # é‡æ–°çµ„åˆ
    content = ' '.join(cleaned_lines)
    
    # ä¿®å¾©å°¾éš¨é€—è™Ÿ
    content = fix_json_trailing_commas(content)
    
    # ç¢ºä¿æ­£ç¢ºé—œé–‰
    open_braces = content.count('{')
    close_braces = content.count('}')
    open_brackets = content.count('[')
    close_brackets = content.count(']')
    
    # æ·»åŠ ç¼ºå¤±çš„æ‹¬è™Ÿ
    if open_braces > close_braces:
        content += '}' * (open_braces - close_braces)
    if open_brackets > close_brackets:
        content += ']' * (open_brackets - close_brackets)
    
    return content

def extract_news_data(json_data):
    """
    ä»JSONæ•°æ®ä¸­æå–æ–°é—»IDã€æ ‡é¢˜å’Œæ‘˜è¦
    """
    try:
        # æ¸…ç†ä¸¦è§£æJSONæ•°æ®
        json_data = json_data.strip()
        
        # ä½¿ç”¨é€²éšä¿®å¾©åŠŸèƒ½
        json_data = advanced_json_fix(json_data)
        
        data = json.loads(json_data)
        print(f"âœ… JSON è§£ææˆåŠŸï¼Œé ‚ç´šéµ: {list(data.keys())}")
        
        news_list = []
        
        # æ£€æŸ¥JSONç»“æ„
        if 'items' in data and 'data' in data['items']:
            news_items = data['items']['data']
            print(f"ğŸ“° æ‰¾åˆ° {len(news_items)} æ¢æ–°èé …ç›®")
            
            # éå†æ¯æ¡æ–°é—»
            for idx, item in enumerate(news_items, 1):
                print(f"ğŸ” è™•ç†ç¬¬ {idx} æ¢æ–°è...")
                
                # æª¢æŸ¥å¿…è¦æ¬„ä½
                required_fields = ['newsId', 'title', 'summary']
                missing_fields = [field for field in required_fields if field not in item]
                
                if not missing_fields:
                    news_info = {
                        'newsId': str(item['newsId']),
                        'title': item['title'].strip(),
                        'summary': item['summary'].strip(),
                        'publishAt': item.get('publishAt', ''),
                        'categoryName': item.get('categoryName', 'æœªåˆ†é¡'),
                        'link': f"https://news.cnyes.com/news/id/{item['newsId']}"
                    }
                    news_list.append(news_info)
                    print(f"âœ… æˆåŠŸæå–: {item['title'][:50]}...")
                else:
                    print(f"âŒ ç¬¬ {idx} æ¢æ–°èç¼ºå°‘æ¬„ä½: {missing_fields}")
                    print(f"   å¯ç”¨æ¬„ä½: {list(item.keys())}")
        else:
            print(f"âŒ JSONçµæ§‹ä¸ç¬¦åˆé æœŸ")
            print(f"   é ‚ç´šéµ: {list(data.keys())}")
            
            # å˜—è©¦å…¶ä»–å¯èƒ½çš„çµæ§‹
            if 'data' in data and isinstance(data['data'], list):
                print("ğŸ”„ å˜—è©¦ç›´æ¥å¾ 'data' é™£åˆ—æå–...")
                for item in data['data']:
                    if all(field in item for field in ['newsId', 'title', 'summary']):
                        news_info = {
                            'newsId': str(item['newsId']),
                            'title': item['title'].strip(),
                            'summary': item['summary'].strip(),
                            'publishAt': item.get('publishAt', ''),
                            'categoryName': item.get('categoryName', 'æœªåˆ†é¡'),
                            'link': f"https://news.cnyes.com/news/id/{item['newsId']}"
                        }
                        news_list.append(news_info)
        
        return news_list
    
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æéŒ¯èª¤: {str(e)}")
        print(f"   éŒ¯èª¤ä½ç½®: è¡Œ {getattr(e, 'lineno', 'æœªçŸ¥')}, åˆ— {getattr(e, 'colno', 'æœªçŸ¥')}")
        
        # å˜—è©¦æˆªå–åˆ°éŒ¯èª¤ä½ç½®å‰çš„æœ‰æ•ˆéƒ¨åˆ†
        try:
            error_pos = getattr(e, 'pos', 0)
            if error_pos > 100:  # å¦‚æœæœ‰è¶³å¤ çš„å…§å®¹
                # å˜—è©¦æ‰¾åˆ°æœ€å¾Œä¸€å€‹å®Œæ•´çš„å°è±¡
                truncated = json_data[:error_pos-10]  # ç¨å¾®å¾€å‰ä¸€é»
                
                # æ‰¾åˆ°æœ€å¾Œä¸€å€‹å®Œæ•´çš„ }
                last_brace = truncated.rfind('}')
                if last_brace > 0:
                    truncated = truncated[:last_brace+1]
                    print("ğŸ”„ å˜—è©¦ä½¿ç”¨æˆªå–çš„éƒ¨åˆ†...")
                    try:
                        data = json.loads(truncated)
                        print("âœ… æˆªå–éƒ¨åˆ†è§£ææˆåŠŸï¼")
                        # é‡æ–°è™•ç†æˆªå–çš„æ•¸æ“š
                        return extract_news_data(truncated)
                    except:
                        pass
        except:
            pass
            
        return []
    except Exception as e:
        print(f"âŒ å…¶ä»–éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return []

def read_json_file(file_path):
    """ä»æ–‡ä»¶è¯»å–JSONæ•°æ®"""
    try:
        if not os.path.exists(file_path):
            print(f"âŒ æ–‡ä»¶ {file_path} ä¸å­˜åœ¨")
            return ""
            
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
            print(f"âœ… æˆåŠŸè®€å–æª”æ¡ˆï¼Œé•·åº¦: {len(content)} å­—ç¬¦")
            return content
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶é”™è¯¯: {e}")
        return ""

def validate_and_fix_json(file_path):
    """é©—è­‰ä¸¦å˜—è©¦ä¿®å¾© JSON æ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
        
        print("ğŸ”§ å˜—è©¦ä¿®å¾© JSON æ–‡ä»¶...")
        
        # ä½¿ç”¨é€²éšä¿®å¾©åŠŸèƒ½
        fixed_content = advanced_json_fix(content)
        
        # å˜—è©¦è§£æä¿®å¾©å¾Œçš„å…§å®¹
        try:
            json.loads(fixed_content)
            print(f"âœ… æˆåŠŸä¿®å¾© JSON æ ¼å¼")
            
            # ä¿å­˜ä¿®å¾©å¾Œçš„æ–‡ä»¶
            backup_file = file_path + '.backup'
            with open(backup_file, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"ğŸ“‹ åŸæ–‡ä»¶å‚™ä»½ç‚º: {backup_file}")
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(fixed_content)
            print(f"ğŸ’¾ å·²ä¿å­˜ä¿®å¾©å¾Œçš„æ–‡ä»¶")
            
            return True
        except json.JSONDecodeError as e:
            print(f"âŒ æ¨™æº–ä¿®å¾©å¤±æ•—: {e}")
            
            # å˜—è©¦æˆªå–ä¿®å¾©
            error_pos = getattr(e, 'pos', len(fixed_content))
            if error_pos > 100:
                print("ğŸ”„ å˜—è©¦æˆªå–ä¿®å¾©...")
                # æ‰¾åˆ°éŒ¯èª¤ä½ç½®å‰çš„æœ€å¾Œä¸€å€‹å®Œæ•´çµæ§‹
                truncated = fixed_content[:error_pos-10]
                last_brace = truncated.rfind('}')
                
                if last_brace > 0:
                    truncated = truncated[:last_brace+1]
                    try:
                        json.loads(truncated)
                        print("âœ… æˆªå–ä¿®å¾©æˆåŠŸ")
                        
                        with open(file_path, 'w', encoding='utf-8') as f:
                            f.write(truncated)
                        return True
                    except:
                        pass
            
            return False
        
    except Exception as e:
        print(f"âŒ ä¿®å¾©éç¨‹å‡ºéŒ¯: {e}")
        return False

def main():
    print("=== é‰…äº¨ç¶²æ–°èè³‡æ–™æå–å·¥å…· ===\n")
    
    # æ£€æŸ¥å¹¶å°è¯•ä¿®å¤JSONæ–‡ä»¶
    if os.path.exists('paste.txt'):
        # å…ˆå˜—è©¦è®€å–åŸæ–‡ä»¶
        json_data = read_json_file('paste.txt')
        
        if json_data:
            try:
                # å…ˆå˜—è©¦é€²éšä¿®å¾©
                cleaned_data = advanced_json_fix(json_data.strip())
                json.loads(cleaned_data)
                json_data = cleaned_data
                print("âœ… æˆåŠŸä¿®å¾© JSON æ ¼å¼å•é¡Œ")
            except json.JSONDecodeError:
                print("ğŸ”§ æª¢æ¸¬åˆ° JSON æ ¼å¼å•é¡Œï¼Œå˜—è©¦å®Œæ•´ä¿®å¾©...")
                if validate_and_fix_json('paste.txt'):
                    # é‡æ–°è®€å–ä¿®å¾©å¾Œçš„æ–‡ä»¶
                    json_data = read_json_file('paste.txt')
                else:
                    print("âŒ æ¨™æº–ä¿®å¾©å¤±æ•—ï¼Œå˜—è©¦å¼·åˆ¶æå–...")
                    # æœ€å¾Œå˜—è©¦ï¼šç›´æ¥æå–å¯èƒ½çš„æ•¸æ“š
                    json_data = json_data.strip()
    else:
        print("âŒ æ‰¾ä¸åˆ° paste.txt æ–‡ä»¶")
        return
    
    if json_data:
        # æå–æ–°é—»æ•°æ®
        news_list = extract_news_data(json_data)
        
        if news_list:
            print(f"\nğŸ‰ æˆåŠŸæå– {len(news_list)} æ¢æ–°è:")
            print("=" * 80)
            
            for i, news in enumerate(news_list, 1):
                print(f"\nğŸ“° æ–°è {i}:")
                print(f"   ğŸ“‹ ID: {news['newsId']}")
                print(f"   ğŸ“ æ¨™é¡Œ: {news['title']}")
                print(f"   ğŸ“„ æ‘˜è¦: {news['summary'][:100]}{'...' if len(news['summary']) > 100 else ''}")
                print(f"   ğŸ·ï¸  åˆ†é¡: {news['categoryName']}")
                print(f"   ğŸ”— é€£çµ: {news['link']}")
                
            # ä¿å­˜åˆ°CSVæ–‡ä»¶
            df = pd.DataFrame(news_list)
            output_file = 'cnyes_news_extract.csv'
            df.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"\nâœ… è³‡æ–™å·²ä¿å­˜åˆ° {output_file}")
            
            # é¡¯ç¤ºCSVæª”æ¡ˆè³‡è¨Š
            print(f"ğŸ“Š CSVæª”æ¡ˆåŒ…å« {len(df)} ç­†è¨˜éŒ„ï¼Œ{len(df.columns)} å€‹æ¬„ä½")
            print(f"ğŸ“‚ æ¬„ä½åç¨±: {', '.join(df.columns)}")
            
        else:
            print("âŒ æ²’æœ‰æå–åˆ°ä»»ä½•æ–°èè³‡æ–™")
    else:
        print("âŒ ç„¡æ³•è®€å–è³‡æ–™")

if __name__ == "__main__":
    main()

[
    {
        "type": "command",
        "details": {
            "key": "python.execInTerminal"
        }
    }
]
import requests
import pandas as pd
import datetime as dt
import json
import os

def scrape_cnyes_news():
    """çˆ¬å–é‰…äº¨ç¶²æ–°èä¸¦é©—è­‰æˆåŠŸ"""
    try:
        print("ğŸš€ é–‹å§‹çˆ¬å–é‰…äº¨ç¶²æ–°è...")
        
        data = []
        url = "https://api.cnyes.com/media/api/v1/newslist/category/headline"
        payload = {
            "page": 1,
            "limit": 30,
            "isCategoryHeadline": 1,
            "startAt": int((dt.datetime.today() - dt.timedelta(days=10)).timestamp()),
            "endAt": int(dt.datetime.today().timestamp())
        }
        
        # ç²å–ç¬¬ä¸€é 
        print("ğŸ“¥ æ­£åœ¨ç²å–ç¬¬1é ...")
        res = requests.get(url, params=payload, timeout=30)
        res.raise_for_status()  # æª¢æŸ¥HTTPéŒ¯èª¤
        
        jd = json.loads(res.text)
        data.append(pd.DataFrame(jd['items']['data']))
        
        total_pages = jd['items']['last_page']
        print(f"ğŸ“„ ç¸½å…±ç™¼ç¾ {total_pages} é ")
        
        # ç²å–å…¶ä»–é é¢
        for i in range(2, total_pages + 1):
            print(f"ğŸ“¥ æ­£åœ¨ç²å–ç¬¬ {i}/{total_pages} é ...")
            payload["page"] = i
            
            res = requests.get(url, params=payload, timeout=30)
            res.raise_for_status()
            jd = json.loads(res.text)
            data.append(pd.DataFrame(jd['items']['data']))
        
        # è™•ç†è³‡æ–™
        df = pd.concat(data, ignore_index=True)
        df = df[['newsId', 'title', 'summary']]
        df['link'] = df['newsId'].apply(lambda x: f'https://m.cnyes.com/news/id/{x}')
        
        # ä¿å­˜æª”æ¡ˆ
        filename = 'news.csv'
        df.to_csv(filename, encoding='utf-8-sig', index=False)
        
        # é©—è­‰æˆåŠŸ
        if os.path.exists(filename):
            file_size = os.path.getsize(filename)
            print(f"âœ… çˆ¬å–æˆåŠŸ!")
            print(f"ğŸ“Š ç¸½å…±ç²å– {len(df)} ç­†æ–°è")
            print(f"ğŸ’¾ æª”æ¡ˆå·²ä¿å­˜: {filename} ({file_size} bytes)")
            print(f"ğŸ“‹ æ¬„ä½: {', '.join(df.columns)}")
            
            # é¡¯ç¤ºç¯„ä¾‹
            print("\nğŸ“° æ–°èç¯„ä¾‹:")
            for i, row in df.head(3).iterrows():
                print(f"  {i+1}. {row['title'][:50]}...")
            
            return True
        else:
            print("âŒ æª”æ¡ˆä¿å­˜å¤±æ•—")
            return False
            
    except requests.RequestException as e:
        print(f"âŒ ç¶²è·¯è«‹æ±‚éŒ¯èª¤: {e}")
        return False
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æéŒ¯èª¤: {e}")
        return False
    except Exception as e:
        print(f"âŒ æœªçŸ¥éŒ¯èª¤: {e}")
        return False

if __name__ == "__main__":
    success = scrape_cnyes_news()
    if success:
        print("ğŸ‰ ç¨‹å¼åŸ·è¡ŒæˆåŠŸ!")
    else:
        print("ğŸ’¥ ç¨‹å¼åŸ·è¡Œå¤±æ•—!")